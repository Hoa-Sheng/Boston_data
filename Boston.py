# -*- coding: utf-8 -*-
"""TP5-6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tq-3MzddyihwOZnIHgt2ZfNPwYI068oy

# TP 5

# **Partie I**

On commence par charger les données du dataset et on les affiche.
"""

from sklearn import datasets
import numpy as np
import matplotlib.pyplot as plt

boston = datasets.load_boston()
print(boston)
print(boston.target)

"""# **Partie II**"""

print(boston.data.mean(0))
print(boston.data.std(0))
print(boston.data.min(0))
print(boston.data.max(0))

"""Ensuite nous calculons les mesures statistiques de nos variables. Grâce a l'ecart type on peut voir la dispersion des données. Ainsi qu'avec la mediane et les quartiles nous pouvons voir le repartissions des données. Et ensuite nous affichons le Boxplot qui reunis toutes ces statistiques."""

plt.boxplot(boston.data, 0)

"""Nous voyons sur les boxplots que la 5ème colonne qui correspond a la concentration en acide nitrique n'a presque pas d' étendu elle ne fait qu'un point ce qui parait coherent, a l'inverse la 10ème colonne correspondant au taux d'imposition possède une plus grande disparité, de plus nous voyons que la mediane est basse ce qui signifie que beaucoup de personne sont entre le bas du rectangle et la ligne orange. On peut voir aussi que le 13ème colonne, celle du ratio élèves professeur à une faible disparité."""

a=np.histogram(boston.data)

plt.hist(a, bins='auto')

"""Sur l'histogramme, on peut voir beaucoup de valeur dont certain à 5000. Mais la majorité sont proche de 0"""

from numpy import cov
covariance = cov(boston.data)
print(covariance)

"""La covariance crée un lien, une corrélation entre les données, on voit que les valeurs sont plutôt proche les unes des autres la corrélation est pour chaque colonne approximativement équivalente.

# **Partie III**
"""

x = boston.data[:,5]
a= np.quantile(boston.data[:,5], 0.25)
b= np.quantile(boston.data[:,5], 0.75)
print("Quartile inférieur:", a)
print("Médiane:", np.quantile(boston.data[:,5], 0.5))
print("Quartile supérieur:", b)
plt.boxplot(boston.data[:,5], 0)
x=np.sort(x)
poors, median1, median2, expensive= np.array_split(x, 4)
print("Poors: ", poors)

print("Median: ", median1)

print(median2)

print("expensive: ", expensive)

"""On a decidé de séparer les données de logement en 3 catégories à partir de a boîte à moustache. En supposant que le 1er quart de la population possède un logement avec peu de pieces ("poors"), les 50% autour de la mediane ont un nombre de pièces médian et enfin le dernier quart a le plus de pièces ("expensives"). On voit dans la boite à moustache que les valeurs sont plutôt concentré, et qu'il y a plus de logement très grand que très petit (symbolisé par les points au dessus et en dessous)."""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

x = boston.data[:,5]
poors, median1, median2, expensive= np.array_split(x, 4)
y=boston.target
first, second, third, fourth= np.array_split(y, 4)
plt.scatter(poors ,first, color='green')
plt.scatter(median1 , second, color='blue')
plt.scatter(median2 , third, color='blue')
plt.scatter(expensive , fourth, color='red')

"""Le nuage de points nous permet de voir la dispersion des données dans ce cas on voit un bloc avec la majorité des points et des valeurs au dessus pour les grands apartement et en dessous pour les plus petit.
La tendance moyenne est plus basse que le milieu du tableau comme vu avec la mediane et la moyenne.
"""

import plotly.express as px

w=boston.data[:,4]
w=np.sort(w)
first1, second2, third3, fourth4= np.array_split(w, 4)


fig= px.scatter_3d(x = poors, y= first, z = first1)

fig=px.scatter_3d(x = median1, y = second, z = second2)

fig=px.scatter_3d(x = median2, y = third, z = third3)

fig=px.scatter_3d(x = expensive, y = fourth, z = fourth4)

fig.show()

from scipy import stats

def predict(x):
   return slope * x + intercept

x=boston.data[:,5]
y=boston.target
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)

model = LinearRegression().fit(boston.data, y)
print(model.score(boston.data, y))



fitLine = predict(x)
plt.scatter(boston.data[:,5], boston.target, color="blue")
plt.plot(x, fitLine, c='r')

"""On voit que la valeur des logements augmente comme ce qui est montrer avec la regression linéaire. On voit aussi des valeurs qui sont plus ou moins eloignée de la droite, on peut supposer qu'elles sont abérrantes

# **Partie IV**

Pour Conclure, on a vu tout d'abord que pour analyser les données que nous avions, nous devons tout d'abord utilisé les outils statistiques afin de voir des tendances se dessiner et si besoin éliminer certaines valeurs aberrantes, en utilisant notament la regression linéaire. Nous pouvons également faire la même manipulation pour un certaine catégorie dans toutes les données que nous avons.
"""